{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.applications.densenet import DenseNet121\n",
    "import keras.backend as K\n",
    "import cv2\n",
    "import os\n",
    "from keras.callbacks import LearningRateScheduler,ReduceLROnPlateau,CSVLogger,ModelCheckpoint\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score,roc_auc_score, cohen_kappa_score\n",
    "from keras.callbacks import Callback\n",
    "from keras.layers import Dense\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Custom callback function to calculate average ROC,F1 and Kappa score\n",
    "class roc_callback(Callback):\n",
    "    def __init__(self,validation_data):\n",
    "        self.x_val = validation_data[0]\n",
    "        self.y_val = validation_data[1]\n",
    "\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "\n",
    "        if(epoch%1==0):\n",
    "            print(\"Calc Roc\")\n",
    "            all_rocs = []\n",
    "            y_pred_val = self.model.predict(self.x_val,verbose=1)\n",
    "\n",
    "            try:\n",
    "                roc_val = roc_auc_score(self.y_val, y_pred_val)\n",
    "                all_rocs.append(roc_val)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            all_rocs = np.array(all_rocs)\n",
    "            mean_roc = np.mean(all_rocs)\n",
    "            \n",
    "            Y_val_kappa=[np.argmax(i) for i in self.y_val]\n",
    "            y_pred_kappa=[np.argmax(i) for i in y_pred_val]\n",
    "                        \n",
    "            avg_f1 = f1_score(Y_val_kappa, y_pred_kappa, average='weighted')\n",
    "            kappa_score = cohen_kappa_score(Y_val_kappa, y_pred_kappa) \n",
    "            \n",
    "            print(\"Mean ROC VAL {0}\".format(mean_roc))\n",
    "            print(\"AVG F1 {0}\".format(avg_f1))\n",
    "            print(\"KAPPA {0}\".format(kappa_score))\n",
    "        return\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X, Y - Load numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_val,Y_train,Y_val=train_test_split(X,Y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=np.array(Y_train)\n",
    "#y_train[np.where(y_train==1)]=1\n",
    "y_train[np.where(y_train==2)]=1\n",
    "\n",
    "y_val=np.array(Y_val)\n",
    "# y_val[np.where(y_val==1)]=0\n",
    "y_val[np.where(y_val==2)]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conversion of labels into One-hot encoding\n",
    "Y_train=to_categorical(y_train,num_classes=2)\n",
    "Y_val=to_categorical(y_val,num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_call = roc_callback((X_val,Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations import (\n",
    "    HorizontalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
    "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
    "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, RandomBrightnessContrast, IAAPiecewiseAffine,\n",
    "    IAASharpen, IAAEmboss, Flip, OneOf, Compose, RandomCrop, CenterCrop\n",
    ")\n",
    "\n",
    "aug = CLAHE(p=1)\n",
    "\n",
    "X=[]\n",
    "for i in X_train:\n",
    "    image = aug(image=i)['image']\n",
    "    X.append(image)\n",
    "    \n",
    "X=np.array(X)\n",
    "print (X.shape)\n",
    "np.save('./X_clahe_fold3.npy', X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.concatenate([X_train, np.load('./X_horizontal_flip_fold3.npy', mmap_mode='r'), np.load('./X_clahe_fold3.npy', mmap_mode='r')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train=np.concatenate([Y_train, Y_train, Y_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations import (\n",
    "    HorizontalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
    "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
    "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, RandomBrightnessContrast, IAAPiecewiseAffine,\n",
    "    IAASharpen, IAAEmboss, Flip, OneOf, Compose, RandomCrop, CenterCrop\n",
    ")\n",
    "\n",
    "aug = OneOf([\n",
    "        HorizontalFlip(p=0.5),\n",
    "        CLAHE(p=0.8)\n",
    "]\n",
    ")\n",
    "\n",
    "def batch_generator(X,y, batch_size=32):\n",
    "    '''\n",
    "    Return a random image from X, y\n",
    "    '''\n",
    "    \n",
    "    while True:\n",
    "        # choose batch_size random images / labels from the data\n",
    "        #idx = np.random.randint(0, X.shape[0], batch_size)\n",
    "        i=0\n",
    "        for idx in np.arange(32,X.shape[0], batch_size):\n",
    "        \n",
    "            im = np.array(X[i:idx])\n",
    "            label = np.array(y[i:idx])\n",
    "            for idx, image in enumerate(im):\n",
    "                image2 = aug(image=image)['image']\n",
    "                image2 = image2[0:130, 40:170]\n",
    "                image2 = cv2.resize(image2, (224,224))\n",
    "                im[idx] = image2\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "            yield im,label\n",
    "            i = idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=10\n",
    "h=10\n",
    "fig=plt.figure(figsize=(16,16))\n",
    "columns = 4\n",
    "rows = 5\n",
    "for i in range(1, columns*rows +1):\n",
    "    #img = np.random.randint(1,5000)\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.imshow(X)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations import (\n",
    "    HorizontalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
    "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
    "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, RandomBrightnessContrast, IAAPiecewiseAffine,\n",
    "    IAASharpen, IAAEmboss, Flip, OneOf, Compose, RandomCrop, CenterCrop\n",
    ")\n",
    "\n",
    "\n",
    "def augment_and_show(aug, image):\n",
    "    image = aug(image=image)['image']\n",
    "    return image\n",
    "#     plt.figure(figsize=(10, 10))\n",
    "#     plt.imshow(image)\n",
    "    \n",
    "aug = HorizontalFlip(p=1)\n",
    "# augment_and_show(aug, X_train[0].astype('uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=10\n",
    "h=10\n",
    "fig=plt.figure(figsize=(16,16))\n",
    "columns = 4\n",
    "rows = 5\n",
    "for i in range(1, columns*rows +1):\n",
    "    #img = np.random.randint(1,5000)\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    a=augment_and_show(aug, X_train[i].astype('uint8'))\n",
    "    plt.imshow(a)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations\n",
    "def augment_and_show(aug, image):\n",
    "    image = aug(image=image)['image']\n",
    "    return image\n",
    "#     plt.figure(figsize=(10, 10))\n",
    "#     plt.imshow(image)\n",
    "    \n",
    "\n",
    "aug = CLAHE(p=1)\n",
    "# augment_and_show(aug, X_train[0].astype('uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=10\n",
    "h=10\n",
    "fig=plt.figure(figsize=(16,16))\n",
    "columns = 4\n",
    "rows = 5\n",
    "for i in range(1, columns*rows +1):\n",
    "    #img = np.random.randint(1,5000)\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    a=augment_and_show(aug, X_train[i].astype('uint8'))\n",
    "    plt.imshow(cv2.resize(a, (224,224)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=10\n",
    "h=10\n",
    "fig=plt.figure(figsize=(16,16))\n",
    "columns = 4\n",
    "rows = 5\n",
    "for i in range(1, columns*rows +1):\n",
    "    #img = np.random.randint(1,5000)\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "#     a=augment_and_show(aug, X_train[i].astype('uint8'))\n",
    "    a=X_train[i][0:130, 40:170].astype('uint8')\n",
    "    plt.imshow(a)\n",
    "#     plt.imshow(cv2.resize(a, (224,224)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imgaug import augmenters as iaa\n",
    "\n",
    "aug = iaa.Sequential([\n",
    "    iaa.OneOf([ ## geometric transform\n",
    "        iaa.Affine(\n",
    "            scale={\"x\": (0.98, 1.02), \"y\": (0.98, 1.04)},\n",
    "            translate_percent={\"x\": (-0.02, 0.02), \"y\": (-0.04, 0.04)},\n",
    "            rotate=(-2, 2),\n",
    "            shear=(-1, 1),\n",
    "        ),\n",
    "        iaa.PiecewiseAffine(scale=(0.001, 0.025)),\n",
    "    ]),\n",
    "    iaa.OneOf([ ## brightness or contrast\n",
    "        iaa.Multiply((0.9, 1.1)),\n",
    "        iaa.ContrastNormalization((0.9, 1.1)),\n",
    "    ]),\n",
    "    iaa.OneOf([ ## blur or sharpen\n",
    "        iaa.GaussianBlur(sigma=(0.0, 0.1)),\n",
    "        iaa.Sharpen(alpha=(0.0, 0.1)),\n",
    "    ]),\n",
    "])\n",
    "\n",
    "def batch_generator(X,y, batch_size=32):\n",
    "    while True:\n",
    "        # choose batch_size random images / labels from the data\n",
    "        #idx = np.random.randint(0, X.shape[0], batch_size)\n",
    "        i=0\n",
    "        for idx in np.arange(32,X.shape[0], batch_size):\n",
    "        \n",
    "            im = np.array(X[i:idx])\n",
    "            label = np.array(y[i:idx])\n",
    "            im = aug.augment_images(im)    #In-place flips\n",
    "            \n",
    "            yield im,label\n",
    "            i = idx\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen=ImageDataGenerator(\n",
    "    horizontal_flip=True,\n",
    "    #vertical_flip=True,\n",
    "    rotation_range=5,\n",
    "    #width_shift_range=0.2,\n",
    "    #height_shift_range=0.2\n",
    ")\n",
    "\n",
    "train_datagen.fit(pad_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model declaration:Densenet \n",
    "dense_model = DenseNet121(weights='imagenet',include_top=False,input_shape=(224,224,3),pooling='avg')\n",
    "preds = Dense(3,activation='sigmoid')(dense_model.output)\n",
    "# preds = Dense(5,activation='softmax')(dense_model.output)\n",
    "model = Model(dense_model.input,preds)\n",
    "# model.load_weights(\"categorical_3class_with_3class_wt_trained_on_fold23.hdf5\")\n",
    "model.layers.pop()\n",
    "preds = Dense(2,activation='softmax')(model.layers[-1].output)\n",
    "model2 = Model(dense_model.input, output=[preds])\n",
    "model2.load_weights(\"complete_data_categorical.hdf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam=Adam(lr=1e-5)\n",
    "model2.compile(optimizer=adam,loss='binary_crossentropy',metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Callback for saving model weights based on minimum Validation loss \n",
    "model_checkpoint = ModelCheckpoint(\n",
    "        os.path.join('./', 'augmentation_test_fold3.hdf5'),\n",
    "        monitor='val_acc', mode='max',save_best_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.1,patience=6, min_delta=0.0001, verbose=1, min_lr=1e-8)\n",
    "\n",
    "#Callback for storing logs of learning rate, loss and accuracy\n",
    "csvlogger=CSVLogger('fold23.csv')\n",
    "\n",
    "callbacks = [model_checkpoint, roc_call,reduce_lr,csvlogger]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Caluculation of class weights based on count of samples in training\n",
    "from sklearn.utils import class_weight\n",
    "y_true=np.argmax(Y_train,axis=-1)\n",
    "weights = class_weight.compute_class_weight('balanced',np.unique(y_true),y_true)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting model on Train and Validation dataset\n",
    "model2.fit(X_train, Y_train, verbose=1, validation_data=(X_val, Y_val),epochs=300, callbacks=callbacks, shuffle=True, class_weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.load_weights('./augmentation_test_fold3.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val=np.load(\"dataset/x_test.npy\")\n",
    "Y_val=np.load(\"y_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p3=model2.predict(X_val, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2=p3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1=p3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final=np.concatenate([p1,p2,p3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for i in p:\n",
    "    if i[1]>0.025:\n",
    "        y_pred.append(1)\n",
    "    else:\n",
    "        y_pred.append(0)\n",
    "        \n",
    "Y[np.where(Y==2)]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print (classification_report(Y, y_pred, target_names=['Healthy', 'Pathology']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "confusion_matrix(Y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_pred).to_csv('./predictions801.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds= pd.read_csv('./predictions8001.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1=y_pred       #80,58,0.0292"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2=y_pred       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(to_categorical(y1), p3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probs = model.predict_proba(X_test)\n",
    "import sklearn.metrics as metrics\n",
    "preds = p3[:,1]\n",
    "y_true = y1\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_true, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "# plt.savefig('3_class_ROC_curve_1e-6.png',dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y1, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=np.concatenate([p1,p2,p3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for i in p:\n",
    "    if i[1]>0.0115:\n",
    "        y_pred.append(1)\n",
    "    else:\n",
    "        y_pred.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.array(y_pred)).to_csv('./final_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
